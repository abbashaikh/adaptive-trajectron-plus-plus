{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "# from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trajdata import AgentBatch, AgentType, UnifiedDataset#, SceneBatch\n",
    "# from trajdata.utils.batch_utils import SceneTimeBatcher\n",
    "from trajdata.data_structures.scene_metadata import Scene as trajdata_Scene\n",
    "# from trajdata.data_structures.state import StateArray, StateTensor\n",
    "from trajdata.simulation import SimulationScene#, sim_metrics, sim_stats, sim_vis\n",
    "from trajdata.visualization.vis import plot_agent_batch\n",
    "\n",
    "# import trajectron.evaluation as evaluation\n",
    "import trajectron.visualization as vis\n",
    "# from trajectron.argument_parser import args\n",
    "from trajectron.model.online.online_trajectron import OnlineTrajectron\n",
    "from trajectron.model.model_registrar import ModelRegistrar\n",
    "# from trajectron.environment import Environment, Scene, Node, DoubleHeaderNumpyArray, SceneGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_device = None\n",
    "arg_seed = None\n",
    "\n",
    "if not torch.cuda.is_available() or arg_device == 'cpu':\n",
    "    arg_device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.device_count() == 1:\n",
    "        # If you have CUDA_VISIBLE_DEVICES set, which you should,\n",
    "        # then this will prevent leftover flag arguments from\n",
    "        # messing with the device allocation.\n",
    "        arg_device = 'cuda:0'\n",
    "\n",
    "    arg_device = torch.device(arg_device)\n",
    "\n",
    "if arg_device is None:\n",
    "    arg_device = 'cpu'\n",
    "\n",
    "if arg_seed is not None:\n",
    "    random.seed(arg_seed)\n",
    "    np.random.seed(arg_seed)\n",
    "    torch.manual_seed(arg_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(arg_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '/home/abbas/Projects/trajectron/adaptive-trajectron-plus-plus/experiments/pedestrians/kf_models'\n",
    "model_dir = os.path.join(log_dir, 'eth_1mode_base_tpp-20_Jan_2023_17_38_09')\n",
    "\n",
    "# Load hyperparameters from json\n",
    "conf = 'config.json'\n",
    "config_file = os.path.join(model_dir, conf)\n",
    "if not os.path.exists(config_file):\n",
    "    raise ValueError('Config json not found!')\n",
    "with open(config_file, 'r') as conf_json:\n",
    "    hyperparams = json.load(conf_json)\n",
    "\n",
    "output_save_dir = os.path.join(model_dir, 'pred_figs')\n",
    "pathlib.Path(output_save_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['eupeds_eth-zurich-train', 'eupeds_eth-cyprus-train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Scenes from eupeds_eth: 100%|██████████| 2/2 [00:00<00:00, 2528.21it/s]\n",
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 4922.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Agent Data Index (8 CPUs): 100%|██████████| 1/1 [00:00<00:00, 147.36it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 1/1 [00:00<00:00, 3045.97it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load evaluation environments and scenes\n",
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    # desired_data=[\"eupeds_eth-test_loo\"],\n",
    "    desired_data=[\"eupeds_eth-train\"],\n",
    "    centric =\"agent\",\n",
    "    history_sec=(hyperparams[\"history_sec\"], hyperparams[\"history_sec\"]),\n",
    "    future_sec=(hyperparams[\"prediction_sec\"], hyperparams[\"prediction_sec\"]),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    standardize_data=True,\n",
    "    data_dirs={  # Remember to change this to match your filesystem!\n",
    "        \"eupeds_eth\": \"/home/abbas/Projects/trajectron/datasets/eth_ucy\",\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = UnifiedDataset(\n",
    "#     # desired_data=[\"eupeds_eth-test_loo\"],\n",
    "#     desired_data=[\"eupeds_eth-train\"],\n",
    "#     centric =\"agent\",\n",
    "#     history_sec=(hyperparams[\"history_sec\"], hyperparams[\"history_sec\"]),\n",
    "#     future_sec=(hyperparams[\"prediction_sec\"], hyperparams[\"prediction_sec\"]),\n",
    "#     agent_interaction_distances=attention_radius,\n",
    "#     incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "#     incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "#     only_predict=[AgentType.PEDESTRIAN],\n",
    "#     no_types=[AgentType.UNKNOWN],\n",
    "#     num_workers=hyperparams[\"preprocess_workers\"],\n",
    "#     cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "#     standardize_data=False,\n",
    "#     data_dirs={  # Remember to change this to match your filesystem!\n",
    "#         \"eupeds_eth\": \"/home/abbas/Projects/trajectron/datasets/eth_ucy\",\n",
    "#     },\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy environment with a single scene that contains information about the world.\n",
    "# When using this code, feel free to use whichever scene index or initial timestep you wish.\n",
    "scene_idx = 0\n",
    "\n",
    "# You need to have at least acceleration, so you want 2 timesteps of prior data, e.g. [0, 1],\n",
    "# so that you can immediately start incremental inference from the 3rd timestep onwards.\n",
    "init_timestep = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the desired scene\n",
    "# timestep = 16\n",
    "\n",
    "sim_env_name = \"eupeds_eth_st\"\n",
    "scene_name = \"biwi_eth-test_loo\"\n",
    "desired_scene: trajdata_Scene = dataset.get_scene(scene_idx)\n",
    "\n",
    "sim_scene: SimulationScene = SimulationScene(\n",
    "            env_name=sim_env_name,\n",
    "            scene_name=scene_name,\n",
    "            scene=desired_scene,\n",
    "            dataset=dataset,\n",
    "            init_timestep=2,\n",
    "            freeze_agents=True,\n",
    "            )\n",
    "# obs: AgentBatch = sim_scene.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize online trajectron\n",
    "\n",
    "model_registrar = ModelRegistrar(model_dir, arg_device)\n",
    "\n",
    "trajectron = OnlineTrajectron(model_registrar,\n",
    "                                hyperparams,\n",
    "                                arg_device)\n",
    "\n",
    "agent_types = [AgentType.PEDESTRIAN]\n",
    "edge_types = [(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)]\n",
    "# print(edge_types)\n",
    "# print(agent_type)\n",
    "# print(edge_types[0])\n",
    "\n",
    "epoch = 5\n",
    "model_path = pathlib.Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "checkpoint = torch.load(model_path, map_location=arg_device)\n",
    "trajectron.load_state_dict(checkpoint[\"model_state_dict\"], strict=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectron.set_environment(agent_types, edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep: 2\n",
      "Agent: 1\n",
      "Agent: 2\n",
      "Timestep: 3\n",
      "Agent: 1\n",
      "Agent: 2\n",
      "Timestep: 4\n",
      "Agent: 1\n",
      "Agent: 2\n",
      "Timestep: 5\n",
      "Agent: 2\n",
      "Agent: 3\n",
      "Timestep: 6\n",
      "Agent: 2\n",
      "Agent: 3\n",
      "Timestep: 7\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m obs: AgentBatch \u001b[38;5;241m=\u001b[39m sim_scene\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     19\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 20\u001b[0m dists, preds \u001b[38;5;241m=\u001b[39m \u001b[43mtrajectron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincremental_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     29\u001b[0m detailed_preds_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/trajectron/adaptive-trajectron-plus-plus/src/trajectron/model/online/online_trajectron.py:151\u001b[0m, in \u001b[0;36mOnlineTrajectron.incremental_forward\u001b[0;34m(self, obs, maps, prediction_horizon, num_samples, robot_present_and_future, z_mode, gmm_mode, full_dist, all_z_sep, run_models)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# if len(robot_present_and_future.shape) == 2:\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m#     robot_present_and_future = robot_present_and_future[\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m#         np.newaxis, :\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m#     robot_present_and_future, dtype=torch.float, device=self.device\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_models_dict:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_models_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# If num_predicted_timesteps or num_samples == 0 then do not run the decoder at all,\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# just update the encoder LSTMs.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_horizon \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m num_samples \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/trajectron/adaptive-trajectron-plus-plus/src/trajectron/model/online/online_mgcvae.py:423\u001b[0m, in \u001b[0;36mOnlineMultimodalGenerativeCVAE.encoder_forward\u001b[0;34m(self, obs, agent_name)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# index of the agent being tracked (among all agents in scene at current timestep)\u001b[39;00m\n\u001b[1;32m    421\u001b[0m idx \u001b[38;5;241m=\u001b[39m obs\u001b[38;5;241m.\u001b[39magent_name\u001b[38;5;241m.\u001b[39mindex(agent_name)\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, x_nr_t, _, y_r, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_encoded_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# This is the old n_s_t0 (just the state at the current timestep, t=0).\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_s_t0: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m obs\u001b[38;5;241m.\u001b[39magent_hist[idx, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/Projects/trajectron/adaptive-trajectron-plus-plus/src/trajectron/model/online/online_mgcvae.py:319\u001b[0m, in \u001b[0;36mOnlineMultimodalGenerativeCVAE.obtain_encoded_tensors\u001b[0;34m(self, mode, obs, idx)\u001b[0m\n\u001b[1;32m    317\u001b[0m neigh_hist \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m, num_neigh, max_hist_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_length), \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m neigh_idx, hist_len \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(neigh_hist_len):\n\u001b[0;32m--> 319\u001b[0m     neigh_hist[\u001b[38;5;241m0\u001b[39m, neigh_idx, :hist_len, :] \u001b[38;5;241m=\u001b[39m \u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneigh_hist\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneigh_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mhist_len\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    321\u001b[0m encoded_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_edge(\n\u001b[1;32m    322\u001b[0m     mode,\n\u001b[1;32m    323\u001b[0m     node_history_st,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m     num_neigh,\n\u001b[1;32m    329\u001b[0m )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m#####################\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Encode Node Edges #\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m#####################\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/trajectron/adaptive-trajectron-plus-plus/unified-av-data-loader/src/trajdata/data_structures/state.py:379\u001b[0m, in \u001b[0;36mStateTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    378\u001b[0m new_class \u001b[38;5;241m=\u001b[39m Tensor\n\u001b[0;32m--> 379\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m StateTensor\u001b[38;5;241m.\u001b[39mCAPTURED_FUNCS:\n\u001b[1;32m    382\u001b[0m     new_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/adaptive-trajectron/lib/python3.9/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "import matplotlib.patheffects as pe\n",
    "from trajectron.utils import convert_to_world_tf\n",
    "\n",
    "cmap = [\"k\", \"b\", \"y\", \"g\", \"r\"]\n",
    "\n",
    "for t in range(init_timestep+1, sim_scene.scene.length_timesteps):\n",
    "    print(f\"Timestep: {t}\")\n",
    "\n",
    "    try:\n",
    "        sim_scene: SimulationScene = SimulationScene(\n",
    "        env_name=sim_env_name,\n",
    "        scene_name=scene_name,\n",
    "        scene=desired_scene,\n",
    "        dataset=dataset,\n",
    "        init_timestep=t,\n",
    "        freeze_agents=True,\n",
    "        )\n",
    "        obs: AgentBatch = sim_scene.reset()\n",
    "\n",
    "        start = time.time()\n",
    "        dists, preds = trajectron.incremental_forward(\n",
    "            obs=obs,\n",
    "            maps=None,\n",
    "            prediction_horizon=6,\n",
    "            num_samples=1,\n",
    "            full_dist=True\n",
    "        )\n",
    "        end = time.time()\n",
    "\n",
    "        detailed_preds_dict = dict()\n",
    "        history_world_frame = dict()\n",
    "        future_world_frame = dict()\n",
    "        preiction_world_frame = dict()\n",
    "        for idx, name in enumerate(obs.agent_name):\n",
    "            if name in preds:\n",
    "                detailed_preds_dict[name] = preds[name]\n",
    "                history, future, prediction = convert_to_world_tf(preds, obs, idx)\n",
    "                history_world_frame[name] = history\n",
    "                future_world_frame[name] = future\n",
    "                preiction_world_frame[name] = prediction\n",
    "\n",
    "    except ValueError as e:\n",
    "        if str(e)==f\"Initial timestep {t} contains no agents after filtering. Please choose another initial timestep.\":\n",
    "            obs = None\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # print(\"t=%d: took %.2f s (= %.2f Hz) w/ %d nodes\" % (t, end - start,\n",
    "    #                                                     1. / (end - start), len(obs.agent_name)))\n",
    "                                                        # trajectron.scene_graph.get_num_edges()))\n",
    "\n",
    "    ## initiate plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(-15, 15)\n",
    "    ax.set_ylim(-12, 12)\n",
    "\n",
    "    # for legend\n",
    "    ax.plot([], [], \"k--\", label='History')\n",
    "    ax.plot([], [], \n",
    "            color=cmap[2],  # '2' for PEDESTRIAN prediction\n",
    "            linewidth=0.2,\n",
    "            alpha=0.7,\n",
    "            label='Prediction')\n",
    "    ax.plot([], [],\n",
    "            \"w--\",\n",
    "            path_effects=[\n",
    "                pe.Stroke(linewidth=2, foreground=\"k\"),\n",
    "                pe.Normal(),\n",
    "            ],\n",
    "            label='Future')\n",
    "    ax.legend()\n",
    "\n",
    "    ## plot\n",
    "    # vis.visualize_distribution(\n",
    "    #     ax,\n",
    "    #     dists)\n",
    "    vis.visualize_prediction(\n",
    "        ax,\n",
    "        obs,\n",
    "        preds)\n",
    "    \n",
    "    \n",
    "    fig.savefig(os.path.join(output_save_dir, f'pred_{t}.pdf'), dpi=300)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive-trajectron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
