{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trajdata import AgentBatch, AgentType, UnifiedDataset, SceneBatch\n",
    "from trajdata.utils.batch_utils import SceneTimeBatcher\n",
    "from trajdata.data_structures.scene_metadata import Scene as trajdata_Scene\n",
    "from trajdata.data_structures.state import StateArray, StateTensor\n",
    "from trajdata.simulation import SimulationScene, sim_metrics, sim_stats, sim_vis\n",
    "from trajdata.visualization.vis import plot_agent_batch\n",
    "\n",
    "import trajectron.evaluation as evaluation\n",
    "import trajectron.visualization as vis\n",
    "# from trajectron.argument_parser import args\n",
    "from trajectron.model.online.online_trajectron import OnlineTrajectron\n",
    "from trajectron.model.model_registrar import ModelRegistrar\n",
    "from trajectron.environment import Environment, Scene, Node, DoubleHeaderNumpyArray, SceneGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_device = None\n",
    "arg_seed = None\n",
    "\n",
    "if not torch.cuda.is_available() or arg_device == 'cpu':\n",
    "    arg_device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.device_count() == 1:\n",
    "        # If you have CUDA_VISIBLE_DEVICES set, which you should,\n",
    "        # then this will prevent leftover flag arguments from\n",
    "        # messing with the device allocation.\n",
    "        arg_device = 'cuda:0'\n",
    "\n",
    "    arg_device = torch.device(arg_device)\n",
    "\n",
    "if arg_device is None:\n",
    "    arg_device = 'cpu'\n",
    "\n",
    "if arg_seed is not None:\n",
    "    random.seed(arg_seed)\n",
    "    np.random.seed(arg_seed)\n",
    "    torch.manual_seed(arg_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(arg_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '/home/abbas/Projects/trajectron/adaptive-trajectron-plus-plus/experiments/pedestrians/kf_models'\n",
    "model_dir = os.path.join(log_dir, 'eth_1mode_base_tpp-10_Nov_2024_21_41_22')\n",
    "\n",
    "# Load hyperparameters from json\n",
    "conf = 'config.json'\n",
    "config_file = os.path.join(model_dir, conf)\n",
    "if not os.path.exists(config_file):\n",
    "    raise ValueError('Config json not found!')\n",
    "with open(config_file, 'r') as conf_json:\n",
    "    hyperparams = json.load(conf_json)\n",
    "\n",
    "output_save_dir = os.path.join(model_dir, 'pred_figs')\n",
    "pathlib.Path(output_save_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['test_loo-eupeds_eth']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Scenes from eupeds_eth: 100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]\n",
      "Calculating Agent Data (Serially): 100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Agent Data Index (16 CPUs): 100%|██████████| 1/1 [00:00<00:00, 150.63it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 1/1 [00:00<00:00, 2855.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation environments and scenes\n",
    "attention_radius = defaultdict(\n",
    "    lambda: 20.0\n",
    ")  # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "dataset = UnifiedDataset(\n",
    "    desired_data=[\"eupeds_eth-test_loo\"],\n",
    "    centric =\"agent\",\n",
    "    history_sec=(hyperparams[\"history_sec\"], hyperparams[\"history_sec\"]),\n",
    "    future_sec=(hyperparams[\"prediction_sec\"], hyperparams[\"prediction_sec\"]),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams[\"incl_robot_node\"],\n",
    "    incl_raster_map=hyperparams[\"map_encoding\"],\n",
    "    only_predict=[AgentType.PEDESTRIAN],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=hyperparams[\"preprocess_workers\"],\n",
    "    cache_location=hyperparams[\"trajdata_cache_dir\"],\n",
    "    standardize_data=False,\n",
    "    data_dirs={  # Remember to change this to match your filesystem!\n",
    "        \"eupeds_eth\": \"~/Projects/trajectron/datasets/eth_ucy_peds\",\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.envs)\n",
    "# print(dataset.np_obs_type)\n",
    "# print(dataset.np_state_type)\n",
    "# print(dataset.obs_format)\n",
    "# print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(\n",
    "#     dataset,\n",
    "#     batch_sampler=SceneTimeBatcher(dataset),\n",
    "#     collate_fn=dataset.get_collate_fn(),\n",
    "#     num_workers=4,\n",
    "# )\n",
    "\n",
    "# batch: AgentBatch\n",
    "# for batch in tqdm(dataloader):\n",
    "#     print(batch.scene_ts)\n",
    "\n",
    "# print(batch)\n",
    "# print(batch.agent_name)\n",
    "# print(batch.agent_fut_len)\n",
    "# print(batch.agent_hist_len)\n",
    "# # print(batch.data_idx)\n",
    "# print(batch.scene_ts)\n",
    "# print(batch.curr_agent_state[0])\n",
    "# print(batch.agent_hist[0][-1])\n",
    "# print(batch.agent_fut[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy environment with a single scene that contains information about the world.\n",
    "# When using this code, feel free to use whichever scene index or initial timestep you wish.\n",
    "scene_idx = 0\n",
    "\n",
    "# You need to have at least acceleration, so you want 2 timesteps of prior data, e.g. [0, 1],\n",
    "# so that you can immediately start incremental inference from the 3rd timestep onwards.\n",
    "init_timestep = 1\n",
    "\n",
    "sim_env_name = \"eupeds_eth\"\n",
    "scene_name = \"biwi_eth-test_loo\"\n",
    "desired_scene: Scene = dataset.get_scene(scene_idx)\n",
    "\n",
    "# print(sim_scene.dataset.centric)\n",
    "\n",
    "# obs: AgentBatch = sim_scene.reset()\n",
    "# print(obs.scene_ts)\n",
    "\n",
    "# obs = sim_scene.step()\n",
    "# print(obs.scene_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(sim_scene.scene))\n",
    "# print(sim_scene.scene.agents)\n",
    "# print(sim_scene.scene.agents)\n",
    "# agent_ids = [item.name for item in sim_scene.scene.agents]\n",
    "# print(agent_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('position', 'x'), ('position', 'y'), ('velocity', 'x'), ('velocity', 'y'), ('acceleration', 'x'), ('acceleration', 'y'), ('heading', 'sin'), ('heading', 'cos')]\n"
     ]
    }
   ],
   "source": [
    "state = hyperparams[\"state\"]\n",
    "state_len = sum([len(state[\"PEDESTRIAN\"][k]) for k in state[\"PEDESTRIAN\"]])\n",
    "\n",
    "data_header = list()\n",
    "for quantity, values in state[\"PEDESTRIAN\"].items():\n",
    "    for value in values:\n",
    "        data_header.append((quantity, value))\n",
    "\n",
    "print(data_header)\n",
    "# state_len\n",
    "# clipped_nodes = get_clipped_nodes(obs, agent_ids, obs.curr_agent_state, hyperparams)\n",
    "# for node in clipped_nodes:\n",
    "#     len_list = [len(state[node.type.name][k]) for k in state[node.type.name]]\n",
    "#     print(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_data(obs):\n",
    "    # get data from current observation of nodes\n",
    "    # return array of size [num_agents, state_len]\n",
    "\n",
    "    # sim_scene: SimulationScene = SimulationScene(\n",
    "    #     env_name=sim_env_name,\n",
    "    #     scene_name=scene_name,\n",
    "    #     scene=desired_scene,\n",
    "    #     dataset=dataset,\n",
    "    #     init_timestep=timestep,\n",
    "    #     freeze_agents=True,\n",
    "    #     )\n",
    "    # obs: AgentBatch = sim_scene.reset()\n",
    "    # print(sim_scene.scene.length_timesteps)\n",
    "    # print(sim_scene.scene.length_seconds())\n",
    "\n",
    "    num_agents = len(obs.agent_name)\n",
    "    curr_data = np.zeros((num_agents, state_len))\n",
    "    for idx, agent_state in enumerate(obs.curr_agent_state):\n",
    "        curr_data[idx,:-2] = agent_state[:-1].numpy()\n",
    "        heading = agent_state.heading.item()\n",
    "        curr_data[idx,-2] = np.sin(heading)\n",
    "        curr_data[idx,-1] = np.cos(heading)\n",
    "        \n",
    "    # curr_data = torch.tensor(curr_data)\n",
    "    # curr_data = StateTensor.from_array(curr_data, \"x,y,xd,yd,xdd,ydd,s,c\")\n",
    "    return curr_data\n",
    "\n",
    "# curr_data = get_current_data(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestep = 1\n",
    "# try:\n",
    "#     sim_scene: SimulationScene = SimulationScene(\n",
    "#                 env_name=sim_env_name,\n",
    "#                 scene_name=scene_name,\n",
    "#                 scene=desired_scene,\n",
    "#                 dataset=dataset,\n",
    "#                 init_timestep=timestep,\n",
    "#                 freeze_agents=True,\n",
    "#                 )\n",
    "#     obs: AgentBatch = sim_scene.reset()\n",
    "#     nodes = get_current_data(obs)\n",
    "#     print(nodes)\n",
    "# except ValueError as e:\n",
    "#     if str(e)==f\"Initial timestep {timestep} contains no agents after filtering. Please choose another initial timestep.\":\n",
    "#         nodes = []\n",
    "#         print(nodes)\n",
    "#     else:\n",
    "#         raise\n",
    "# except IndexError as e:\n",
    "#     if str(e)==f\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('--------------------------------')\n",
    "# print(obs.scene_ts)\n",
    "# print('--------------------------------')\n",
    "# print(obs.num_neigh)\n",
    "# print('--------------------------------')\n",
    "# print(obs.scene_ids)\n",
    "# print('--------------------------------')\n",
    "# print(obs.robot_fut_len)\n",
    "# print('--------------------------------')\n",
    "# print(obs.agent_types)\n",
    "# print('--------------------------------')\n",
    "# print(obs.agent_type)\n",
    "# print('--------------------------------')\n",
    "# print(obs.agent_hist_len)\n",
    "# print('--------------------------------')\n",
    "# print(f\"current={obs.curr_agent_state[0]}\")\n",
    "# curr_yaw = obs.curr_agent_state[0].heading.item()\n",
    "# world_from_agent = np.array(\n",
    "#     [\n",
    "#         [np.cos(curr_yaw), np.sin(curr_yaw)],\n",
    "#         [-np.sin(curr_yaw), np.cos(curr_yaw)],\n",
    "#     ]\n",
    "# )\n",
    "# next_state = np.zeros(7,)\n",
    "# next_state[:2] = obs.agent_fut[0, 0, :2] @ world_from_agent + obs.curr_agent_state[0, :2]\n",
    "# next_state[2:4] = obs.agent_fut[0, 0, 2:4] @ world_from_agent + obs.curr_agent_state[0, 2:4]\n",
    "# next_state[4:6] = obs.agent_fut[0, 0, 4:6] @ world_from_agent + obs.curr_agent_state[0, 4:6]\n",
    "# yaw_ac = obs.agent_fut[0, 0].heading.item()\n",
    "# next_state[-1] = curr_yaw + yaw_ac\n",
    "# print(next_state)\n",
    "# print('--------------------------------')\n",
    "# print(obs.agent_fut_len)\n",
    "# print('--------------------------------')\n",
    "# print(f\"hist={obs.agent_hist[0]}\")\n",
    "# print(f\"agents={obs.agent_name}\")\n",
    "# print(obs.dt)\n",
    "# print(obs.agent_fut_len)\n",
    "# print(obs.agent_fut_extent)\n",
    "# print(f\"future={obs.agent_fut[0, 0]}\")\n",
    "# fut_heading = np.arctan2 (obs.agent_fut[0, 0, -2], obs.agent_fut[0, 0, -1])\n",
    "# print(fut_heading)\n",
    "# print(obs.history_pad_dir)\n",
    "# print(obs.neigh_hist)\n",
    "\n",
    "# print(hyperparams[\"state\"][\"PEDESTRIAN\"].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AgentType.PEDESTRIAN/1]\n",
      "[[       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan]\n",
      " [8.46000004 3.58999991 2.7750001  0.5        0.         0.\n",
      "  0.17732476 0.98415239]]\n"
     ]
    }
   ],
   "source": [
    "def get_clipped_nodes(timesteps):\n",
    "    length = len(timesteps)\n",
    "    clipped_nodes: List[Node] = list()\n",
    "    for t in timesteps:\n",
    "        if t<0:\n",
    "            continue\n",
    "        try:\n",
    "            sim_scene: SimulationScene = SimulationScene(\n",
    "                env_name=sim_env_name,\n",
    "                scene_name=scene_name,\n",
    "                scene=desired_scene,\n",
    "                dataset=dataset,\n",
    "                init_timestep=t,\n",
    "                freeze_agents=True,\n",
    "                )\n",
    "            obs: AgentBatch = sim_scene.reset()\n",
    "            curr_data = get_current_data(obs)\n",
    "            for node in clipped_nodes:\n",
    "                if node.id not in obs.agent_name:\n",
    "                    node.data.data = np.vstack((node.data.data, np.full((1, state_len), np.nan)))\n",
    "                else:\n",
    "                    idx = obs.agent_name.index(node.id)\n",
    "                    node.data.data = np.vstack((node.data.data, curr_data[idx]))\n",
    "            \n",
    "            for idx, name in enumerate(obs.agent_name):\n",
    "                if name not in [node.id for node in clipped_nodes]:\n",
    "                    node_data = DoubleHeaderNumpyArray(curr_data[idx].reshape(1, state_len), data_header)\n",
    "                    clipped_nodes.append(Node(\n",
    "                            node_type=AgentType(obs.agent_type[idx].item()),\n",
    "                            node_id = name,\n",
    "                            data=node_data,\n",
    "                            first_timestep=t,\n",
    "                            ))\n",
    "        except ValueError as e:\n",
    "            if str(e)==f\"Initial timestep {t} contains no agents after filtering. Please choose another initial timestep.\":\n",
    "                curr_data = []\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "                \n",
    "    for node in clipped_nodes:\n",
    "        if node.data.data.shape[0]<length:\n",
    "            len_diff = length - node.data.data.shape[0]\n",
    "            node.data.data = np.vstack((np.full((len_diff, state_len), np.nan), node.data.data))\n",
    "                    \n",
    "    return clipped_nodes\n",
    "\n",
    "nodes = get_clipped_nodes(list(range(-7,1)))\n",
    "print(nodes)\n",
    "# print(nodes[1].first_timestep)\n",
    "print(nodes[0].data.data)\n",
    "# print(nodes[2].data.data.shape)\n",
    "# print(nodes[0].data.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clipped_input_dict(timestep):\n",
    "    input_dict: Dict[Node] = dict()\n",
    "    existing_nodes = get_clipped_nodes(list(range(timestep, timestep+1)))\n",
    "    for node in existing_nodes:\n",
    "        input_dict[node] = node.data.data\n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_online_env(obs : AgentBatch, init_timestep):\n",
    "    # test_scene = env.scenes[scene_idx]\n",
    "\n",
    "    online_scene = Scene(timesteps=init_timestep + 1,\n",
    "                         map=None,\n",
    "                         dt=obs.dt[0])\n",
    "    # online_scene.nodes = test_scene.agents\n",
    "    online_scene.nodes = get_clipped_nodes(\n",
    "        timesteps=np.arange(init_timestep - hyperparams['maximum_history_length'],\n",
    "                            init_timestep + 1))\n",
    "    # online_scene.robot = test_scene.robot\n",
    "    online_scene.calculate_scene_graph(attention_radius=attention_radius,\n",
    "                                       edge_addition_filter=hyperparams['edge_addition_filter'],\n",
    "                                       edge_removal_filter=hyperparams['edge_removal_filter'])\n",
    "\n",
    "    env_standardization = {'PEDESTRIAN': {'position': {'x': {'mean': 0, 'std': 1}, 'y': {'mean': 0, 'std': 1}}, 'velocity': {'x': {'mean': 0, 'std': 2}, 'y': {'mean': 0, 'std': 2}}, 'acceleration': {'x': {'mean': 0, 'std': 1}, 'y': {'mean': 0, 'std': 1}}, 'heading': {'sin': {'mean': 0, 'std': 0.01}, 'cos': {'mean': 0, 'std': 0.01}}}}\n",
    "    node_type_list = [AgentType(node_type.item()).name for node_type in obs.agent_type]\n",
    "    return Environment(\n",
    "            node_type_list=node_type_list,\n",
    "            scenes=[online_scene],\n",
    "            attention_radius=attention_radius,\n",
    "            standardization=env_standardization\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([AgentType.PEDESTRIAN/1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scene: SimulationScene = SimulationScene(\n",
    "    env_name=sim_env_name,\n",
    "    scene_name=scene_name,\n",
    "    scene=desired_scene,\n",
    "    dataset=dataset,\n",
    "    init_timestep=init_timestep,\n",
    "    freeze_agents=True,\n",
    "    )\n",
    "obs: AgentBatch = sim_scene.reset()\n",
    "\n",
    "hyperparams[\"maximum_history_length\"] = int((hyperparams[\"history_sec\"]/sim_scene.scene.dt) + 1)\n",
    "online_env = create_online_env(obs, init_timestep)\n",
    "\n",
    "model_registrar = ModelRegistrar(model_dir, arg_device)\n",
    "\n",
    "trajectron = OnlineTrajectron(model_registrar,\n",
    "                                hyperparams,\n",
    "                                arg_device)\n",
    "\n",
    "epoch = 50\n",
    "model_path = pathlib.Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "checkpoint = torch.load(model_path, map_location=arg_device)\n",
    "trajectron.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "# trajectron.set_environment(online_env, init_timestep)\n",
    "trajectron.env = online_env\n",
    "trajectron.scene_graph = SceneGraph(edge_radius=online_env.attention_radius)\n",
    "trajectron.nodes.clear()\n",
    "trajectron.node_data.clear()\n",
    "trajectron.node_models_dict.clear()\n",
    "\n",
    "# trajectron.device\n",
    "\n",
    "for t in range(init_timestep + 1):\n",
    "    trajectron.incremental_forward(\n",
    "        new_inputs_dict=get_clipped_input_dict(t),\n",
    "        maps=None,\n",
    "        run_models=False\n",
    "    )\n",
    "trajectron.node_models_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "encode_total_edge_influence() missing 1 required positional argument: 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m new_xyzh_dict: Dict[\u001b[38;5;28mstr\u001b[39m, StateArray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m dists, preds \u001b[38;5;241m=\u001b[39m \u001b[43mtrajectron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincremental_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_inputs_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_clipped_input_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m: took \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m s (= \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m Hz) w/ \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m nodes and \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m edges\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (t, end \u001b[38;5;241m-\u001b[39m start,\n\u001b[1;32m     14\u001b[0m                                                                 \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m (end \u001b[38;5;241m-\u001b[39m start), \u001b[38;5;28mlen\u001b[39m(trajectron\u001b[38;5;241m.\u001b[39mnodes),\n\u001b[1;32m     15\u001b[0m                                                                 trajectron\u001b[38;5;241m.\u001b[39mscene_graph\u001b[38;5;241m.\u001b[39mget_num_edges()))\n",
      "File \u001b[0;32m~/Projects/trajectron/adaptive-trajectron-plus-plus/src/trajectron/model/online/online_trajectron.py:280\u001b[0m, in \u001b[0;36mOnlineTrajectron.incremental_forward\u001b[0;34m(self, new_inputs_dict, maps, prediction_horizon, num_samples, robot_present_and_future, z_mode, gmm_mode, full_dist, all_z_sep, run_models)\u001b[0m\n\u001b[1;32m    275\u001b[0m     robot_present_and_future \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    276\u001b[0m         robot_present_and_future, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_models_dict:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_models_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_st\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobot_present_and_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaps\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# If num_predicted_timesteps or num_samples == 0 then do not run the decoder at all,\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# just update the encoder LSTMs.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_horizon \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m num_samples \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/trajectron/adaptive-trajectron-plus-plus/src/trajectron/model/online/online_mgcvae.py:485\u001b[0m, in \u001b[0;36mOnlineMultimodalGenerativeCVAE.encoder_forward\u001b[0;34m(self, inputs, inputs_st, inputs_np, robot_present_and_future, maps)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencoder_forward\u001b[39m(\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m, inputs, inputs_st, inputs_np, robot_present_and_future\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, maps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    481\u001b[0m ):\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# Always predicting with the online model.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     mode \u001b[38;5;241m=\u001b[39m ModeKeys\u001b[38;5;241m.\u001b[39mPREDICT\n\u001b[0;32m--> 485\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_encoded_tensors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_st\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobot_present_and_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaps\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_s_t0 \u001b[38;5;241m=\u001b[39m inputs_st[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode]\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent\u001b[38;5;241m.\u001b[39mp_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_z_x(mode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m~/Projects/trajectron/adaptive-trajectron-plus-plus/src/trajectron/model/online/online_mgcvae.py:242\u001b[0m, in \u001b[0;36mOnlineMultimodalGenerativeCVAE.obtain_encoded_tensors\u001b[0;34m(self, mode, inputs, inputs_st, inputs_np, robot_present_and_future, maps)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m#####################\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Encode Node Edges #\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#####################\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     num_neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_neighbors[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode]\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m--> 242\u001b[0m     total_edge_influence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_total_edge_influence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_edges_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_history_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTD \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_history_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m: node_history_encoded,\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_edge_influence\u001b[39m\u001b[38;5;124m\"\u001b[39m: total_edge_influence,\n\u001b[1;32m    249\u001b[0m }\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m################\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Map Encoding #\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m################\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: encode_total_edge_influence() missing 1 required positional argument: 'batch_size'"
     ]
    }
   ],
   "source": [
    "for t in range(init_timestep+1, sim_scene.scene.length_timesteps):\n",
    "    new_xyzh_dict: Dict[str, StateArray] = dict()\n",
    "    \n",
    "    start = time.time()\n",
    "    dists, preds = trajectron.incremental_forward(\n",
    "        new_inputs_dict=get_clipped_input_dict(t),\n",
    "        maps=None,\n",
    "        prediction_horizon=6,\n",
    "        num_samples=1,\n",
    "        full_dist=True\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(\"t=%d: took %.2f s (= %.2f Hz) w/ %d nodes and %d edges\" % (t, end - start,\n",
    "                                                                    1. / (end - start), len(trajectron.nodes),\n",
    "                                                                    trajectron.scene_graph.get_num_edges()))\n",
    "    \n",
    "    detailed_preds_dict = dict()\n",
    "    for name in obs.agent_name:\n",
    "        if name in preds:\n",
    "            detailed_preds_dict[name] = preds[name]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    vis.visualize_distribution(ax,\n",
    "                            dists)\n",
    "    vis.visualize_prediction(ax,\n",
    "                            {t: preds},\n",
    "                            sim_scene.scene.dt,\n",
    "                            hyperparams['maximum_history_length'],\n",
    "                            hyperparams['prediction_horizon'])\n",
    "    \n",
    "    fig.savefig(os.path.join(output_save_dir, f'pred_{t}.pdf'), dpi=300)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive-trajectron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
